{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Building Module\n",
    "\n",
    "This notebook contains utilities for building entity relationship graphs from NLP-processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from typing import List, Dict, Set, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Edge:\n",
    "    \"\"\"Represents an edge between two entities.\"\"\"\n",
    "    source: str\n",
    "    target: str\n",
    "    edge_type: str\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            'source': self.source,\n",
    "            'target': self.target,\n",
    "            'type': self.edge_type\n",
    "        }\n",
    "    \n",
    "    def __hash__(self):\n",
    "        # Make edges undirected for deduplication\n",
    "        return hash(frozenset([self.source, self.target]))\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Edge):\n",
    "            return False\n",
    "        return frozenset([self.source, self.target]) == frozenset([other.source, other.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_entity_pair(entity1: dict, entity2: dict) -> bool:\n",
    "    \"\"\"\n",
    "    Check if an entity pair should be linked.\n",
    "    We skip ORG-ORG pairs and same-entity pairs.\n",
    "    \n",
    "    Args:\n",
    "        entity1: First entity dictionary\n",
    "        entity2: Second entity dictionary\n",
    "    \n",
    "    Returns:\n",
    "        True if the pair is valid\n",
    "    \"\"\"\n",
    "    # Skip same entities\n",
    "    if entity1['name'] == entity2['name']:\n",
    "        return False\n",
    "    \n",
    "    # Skip empty names\n",
    "    if not entity1['name'] or not entity2['name']:\n",
    "        return False\n",
    "    \n",
    "    # Skip ORG-ORG pairs\n",
    "    if entity1['label'] == 'ORG' and entity2['label'] == 'ORG':\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge(entity1: dict, entity2: dict) -> Edge:\n",
    "    \"\"\"\n",
    "    Create an edge between two entities.\n",
    "    \n",
    "    Args:\n",
    "        entity1: First entity dictionary\n",
    "        entity2: Second entity dictionary\n",
    "    \n",
    "    Returns:\n",
    "        Edge object\n",
    "    \"\"\"\n",
    "    edge_type = f\"{entity1['label']}-{entity2['label']}\"\n",
    "    return Edge(\n",
    "        source=entity1['name'],\n",
    "        target=entity2['name'],\n",
    "        edge_type=edge_type\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence_edges(entities: List[dict]) -> Set[Edge]:\n",
    "    \"\"\"\n",
    "    Extract edges from entities that appear in the same sentence.\n",
    "    \n",
    "    Args:\n",
    "        entities: List of entity dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        Set of Edge objects\n",
    "    \"\"\"\n",
    "    edges = set()\n",
    "    \n",
    "    # Group entities by (url, sent_idx)\n",
    "    sentence_entities: Dict[Tuple[str, int], List[dict]] = {}\n",
    "    \n",
    "    for entity in entities:\n",
    "        key = (entity['urls'], entity['sent_idx'])\n",
    "        if key not in sentence_entities:\n",
    "            sentence_entities[key] = []\n",
    "        sentence_entities[key].append(entity)\n",
    "    \n",
    "    # Create edges for entities in the same sentence\n",
    "    for key, sent_entities in sentence_entities.items():\n",
    "        if len(sent_entities) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Generate all pairs\n",
    "        for e1, e2 in combinations(sent_entities, 2):\n",
    "            if is_valid_entity_pair(e1, e2):\n",
    "                edges.add(create_edge(e1, e2))\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coreference_edges(\n",
    "    entities: List[dict],\n",
    "    coref_chains: List[dict]\n",
    ") -> Set[Edge]:\n",
    "    \"\"\"\n",
    "    Extract edges from entities that are linked by coreference chains.\n",
    "    \n",
    "    Args:\n",
    "        entities: List of entity dictionaries\n",
    "        coref_chains: List of coreference chain dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        Set of Edge objects\n",
    "    \"\"\"\n",
    "    edges = set()\n",
    "    \n",
    "    # Group entities by (url, sent_idx)\n",
    "    entity_by_sentence: Dict[Tuple[str, int], List[dict]] = {}\n",
    "    \n",
    "    for entity in entities:\n",
    "        key = (entity['urls'], entity['sent_idx'])\n",
    "        if key not in entity_by_sentence:\n",
    "            entity_by_sentence[key] = []\n",
    "        entity_by_sentence[key].append(entity)\n",
    "    \n",
    "    # Process coreference chains\n",
    "    for chain in coref_chains:\n",
    "        url = chain['url']\n",
    "        chain_sentences = chain['sentences']\n",
    "        \n",
    "        # Collect all entities from sentences in this chain\n",
    "        chain_entities = []\n",
    "        for sent_idx in chain_sentences:\n",
    "            key = (url, sent_idx)\n",
    "            if key in entity_by_sentence:\n",
    "                chain_entities.extend(entity_by_sentence[key])\n",
    "        \n",
    "        # Create edges between entities in the chain\n",
    "        if len(chain_entities) >= 2:\n",
    "            for e1, e2 in combinations(chain_entities, 2):\n",
    "                if is_valid_entity_pair(e1, e2):\n",
    "                    edges.add(create_edge(e1, e2))\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_from_processed_data(processed_articles: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a graph from NLP-processed article data.\n",
    "    \n",
    "    Args:\n",
    "        processed_articles: List of processed article dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns: source, target, type\n",
    "    \"\"\"\n",
    "    all_edges = set()\n",
    "    \n",
    "    # Collect all entities and coreference chains\n",
    "    all_entities = []\n",
    "    all_coref_chains = []\n",
    "    \n",
    "    for article in processed_articles:\n",
    "        all_entities.extend(article.get('entities', []))\n",
    "        all_coref_chains.extend(article.get('coreference_chains', []))\n",
    "    \n",
    "    # Extract edges from same-sentence co-occurrences\n",
    "    sentence_edges = extract_sentence_edges(all_entities)\n",
    "    all_edges.update(sentence_edges)\n",
    "    logger.info(f\"Found {len(sentence_edges)} edges from sentence co-occurrences\")\n",
    "    \n",
    "    # Extract edges from coreference chains\n",
    "    coref_edges = extract_coreference_edges(all_entities, all_coref_chains)\n",
    "    all_edges.update(coref_edges)\n",
    "    logger.info(f\"Found {len(coref_edges)} additional edges from coreference chains\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    edge_list = [edge.to_dict() for edge in all_edges]\n",
    "    \n",
    "    if not edge_list:\n",
    "        return pd.DataFrame(columns=['source', 'target', 'type'])\n",
    "    \n",
    "    df = pd.DataFrame(edge_list)\n",
    "    logger.info(f\"Built graph with {len(df)} total edges\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_statistics(processed_articles: List[Dict[str, Any]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get statistics about extracted entities.\n",
    "    \n",
    "    Args:\n",
    "        processed_articles: List of processed article dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with entity counts\n",
    "    \"\"\"\n",
    "    all_entities = []\n",
    "    for article in processed_articles:\n",
    "        all_entities.extend(article.get('entities', []))\n",
    "    \n",
    "    df = pd.DataFrame(all_entities)\n",
    "    \n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Count occurrences\n",
    "    counts = df.groupby(['name', 'label']).size().reset_index(name='count')\n",
    "    counts = counts.sort_values('count', ascending=False)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Build graph from sample data\n",
    "# sample_processed = [\n",
    "#     {\n",
    "#         'url': 'https://example.com',\n",
    "#         'entities': [\n",
    "#             {'name': 'Elon Musk', 'label': 'PERSON', 'sent_idx': 0, 'start': 0, 'end': 2, 'urls': 'https://example.com'},\n",
    "#             {'name': 'Tesla', 'label': 'ORG', 'sent_idx': 0, 'start': 4, 'end': 5, 'urls': 'https://example.com'},\n",
    "#         ],\n",
    "#         'coreference_chains': []\n",
    "#     }\n",
    "# ]\n",
    "# edges_df = build_graph_from_processed_data(sample_processed)\n",
    "# print(edges_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
